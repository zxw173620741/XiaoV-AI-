from typing import Dict, List, TypedDict
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from ollama import *
import re
import traceback
import json
import os
import time
from tqdm import tqdm
from dotenv import load_dotenv

load_dotenv()
api_url = os.getenv("OLLAMA_URL")
# å®šä¹‰çŠ¶æ€ç»“æ„
class AgentState(TypedDict):
    problem:str
    reasons:List[str]
    knowledge:Dict[str,Dict[str,str]]
    model_advice:Dict[str,str]


class StringOutputLogger:
    def __init__(self):
        self.output_buffer = []
    
    def step_start(self, msg):
        self.output_buffer.append(f"\n{'=' * 50}")
        self.output_buffer.append(f"ğŸš€ {msg}")
        self.output_buffer.append(f"{'=' * 50}")
    
    def step_info(self, msg):
        self.output_buffer.append(f"â„¹ï¸ {msg}")
    
    def step_success(self, msg):
        self.output_buffer.append(f"âœ… {msg}")
    
    def step_warning(self, msg):
        self.output_buffer.append(f"âš ï¸ {msg}")
    
    def show_state(self, state):
        self.output_buffer.append("\nå½“å‰çŠ¶æ€:")
        for key, value in state.items():
            if key == "knowledge" or key == "model_advice":
                self.output_buffer.append(f"  {key}:")
                for subkey, subvalue in value.items():
                    self.output_buffer.append(f"    {subkey}: {str(subvalue)[:80]}...")
            else:
                self.output_buffer.append(f"  {key}: {value}")
    
    def get_output(self):
        return "\n".join(self.output_buffer)
    
    def clear(self):
        self.output_buffer = []


# æ›¿æ¢åŸæ¥çš„VisualLogger
logger = StringOutputLogger()


# çŸ¥è¯†åº“æŸ¥è¯¢å‡½æ•°ï¼ˆä»æ–‡æœ¬æ–‡ä»¶è¯»å–ï¼‰
def query_knowledge_base(problem: str, reason: str) -> dict:
    """ä»æ–‡æœ¬æ–‡ä»¶æŸ¥è¯¢çŸ¥è¯†åº“"""
    logger.step_info(f"æŸ¥è¯¢çŸ¥è¯†åº“: é—®é¢˜={problem}, å¼‚å¸¸æŒ‡æ ‡={reason}")

    # é»˜è®¤è¿”å›ç»“æœ
    default_result = {"solution": "æš‚æ— æ–¹æ¡ˆ", "case": "æ— ç›¸å…³æ¡ˆä¾‹"}

    # çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„ - æ ¹æ®æ‚¨çš„å®é™…ä½ç½®è°ƒæ•´
    knowledge_file = "knowledge_base/sales_knowledge"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(knowledge_file):
        logger.step_warning(f"çŸ¥è¯†åº“æ–‡ä»¶ {knowledge_file} ä¸å­˜åœ¨")
        return default_result

    try:
        # è¯»å–æ•´ä¸ªæ–‡ä»¶å†…å®¹
        with open(knowledge_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # å°†å†…å®¹åˆ†å‰²ä¸ºä¸åŒåŸå› çš„éƒ¨åˆ†
        sections = content.strip().split("\n\n")

        # è§£ææ¯ä¸ªéƒ¨åˆ†
        for section in sections:
            lines = section.strip().split("\n")
            if not lines:
                continue

            # ç¬¬ä¸€è¡Œæ˜¯åŸå› åç§°
            section_reason = lines[0].strip()
            if section_reason != reason:
                continue

            # è§£æè§£å†³æ–¹æ¡ˆå’Œæ¡ˆä¾‹
            solution_lines = []
            case_lines = []
            current_section = None

            for line in lines[1:]:
                if line.startswith("è§£å†³æ–¹æ¡ˆ:"):
                    current_section = "solution"
                    continue
                elif line.startswith("æ¡ˆä¾‹:"):
                    current_section = "case"
                    continue

                if current_section == "solution":
                    solution_lines.append(line.strip())
                elif current_section == "case":
                    case_lines.append(line.strip())

            # æ„å»ºç»“æœ
            result = {
                "solution": "\n".join(solution_lines),
                "case": " ".join(case_lines)
            }

            logger.step_info(f"çŸ¥è¯†åº“è¿”å›ç»“æœ: {result}")
            return result

        # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„åŸå› 
        logger.step_warning(f"æœªæ‰¾åˆ°åŸå›  '{reason}' çš„è§£å†³æ–¹æ¡ˆ")
        return default_result

    except Exception as e:
        logger.step_warning(f"è¯»å–çŸ¥è¯†åº“æ–‡ä»¶å‡ºé”™: {str(e)}")
        return default_result


# è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå»ºè®®
def generate_model_advice(problem: str, reason: str, knowledge: dict) -> dict:
    """ä½¿ç”¨Ollamaå¤§æ¨¡å‹ç”Ÿæˆå»ºè®®å’Œæ¡ˆä¾‹æ€»ç»“"""
    logger.step_info(f"è°ƒç”¨å¤§æ¨¡å‹å¤„ç†: é—®é¢˜={problem}, åŸå› ={reason}")

    # æ„é€ æ›´æ¸…æ™°çš„æç¤ºè¯
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ç”Ÿäº§ç®¡ç†é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ä¸ºé—®é¢˜æä¾›ä¸“ä¸šå»ºè®®ï¼š

    **æ ¸å¿ƒé—®é¢˜**: {problem}
    **å…·ä½“åŸå› **: {reason}

    **çŸ¥è¯†åº“è§£å†³æ–¹æ¡ˆ**:
    {knowledge['solution']}

    **çŸ¥è¯†åº“å…¸å‹æ¡ˆä¾‹**:
    {knowledge['case']}

    è¯·å‚è€ƒæ¡ˆä¾‹ç”Ÿæˆå¯¹è¯¥åŸå› çš„ä¸“ä¸šå»ºè®®,300å­—ä»¥å†…ï¼š
    è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:
    <å»ºè®®å¼€å§‹>
    ä½ çš„å»ºè®®å†…å®¹...
    <å»ºè®®ç»“æŸ>

    """

    try:
        # è°ƒç”¨Ollamaæ¨¡å‹
        logger.step_info("å‘é€æç¤ºè¯ç»™æ¨¡å‹...")
        client = Client(host=api_url)
        response = client.chat(
            model='deepseek-r1:8b',
            messages=[{'role': 'user', 'content': prompt}],
            options={'temperature': 0.3, 'num_ctx': 4096}
        )

        # è·å–æ¨¡å‹å“åº”
        output = response['message']['content']

        advice = ""

        # å°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å†…å®¹
        advice_match = re.search(r'<å»ºè®®å¼€å§‹>([\s\S]*?)<å»ºè®®ç»“æŸ>', output)

        if advice_match:
            advice = advice_match.group(1).strip()
        else:
            logger.step_warning("æœªæ‰¾åˆ°å»ºè®®éƒ¨åˆ†æ ‡è®°")
            # å°è¯•æå–ç¬¬ä¸€éƒ¨åˆ†å†…å®¹ä½œä¸ºå»ºè®®
            if "å»ºè®®" in output or "æ–¹æ¡ˆ" in output:
                advice = output.split("\n\n")[0].strip()
            else:
                advice = "æœªèƒ½æå–å»ºè®®å†…å®¹"

        return {"advice": advice}

    except Exception as e:
        logger.step_warning(f"æ¨¡å‹è°ƒç”¨å‡ºé”™: {str(e)}")
        return {"advice": "æ¨¡å‹è°ƒç”¨å‡ºé”™", "summary": "è¯·æ£€æŸ¥æ¨¡å‹æœåŠ¡"}


# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def process_reason(state: AgentState, config: RunnableConfig) -> AgentState:
    print(f"\n{'=' * 50}")
    print(f"å¼€å§‹åˆ†æå¼‚å¸¸æŒ‡æ ‡: {state['reasons'][0]}")
    reason=state['reasons'][0]
    knowledge=query_knowledge_base(state['problem'],reason)
    model_output=generate_model_advice(state['problem'],reason,knowledge)
    new_state={
        'problem':state['problem'],
        'reasons':state['reasons'][1:],
        'knowledge':{**state['knowledge'],reason:knowledge},
        'model_advice':{**state['model_advice'],reason:model_output['advice']}
    }
    print(f"å¼‚å¸¸æŒ‡æ ‡{reason}å·²ç»åˆ†æå®Œæˆ")
    return new_state



def should_continue(state: AgentState) -> str:
    continue_flag = "continue" if state["reasons"] else "end"
    return continue_flag


# åˆ›å»ºå·¥ä½œæµ
def create_workflow():
    workflow=StateGraph(AgentState)
    workflow.add_node("process_reason",process_reason)
    workflow.add_conditional_edges(
        "process_reason",
        should_continue,{
            "continue":"process_reason",
            "end":END
        }
    )
    workflow.set_entry_point("process_reason")
    return workflow.compile()

# æœ€ç»ˆç»“æœå¯è§†åŒ–
def visualize_final_result(final_state):
    result_lines = []
    result_lines.append("\n" + "=" * 50)
    result_lines.append("âœ¨ æœ€ç»ˆé—®é¢˜åˆ†ææŠ¥å‘Š âœ¨")
    result_lines.append("=" * 50)

    result_lines.append(f"\næ ¸å¿ƒé—®é¢˜: {final_state['problem']}")

    for reason in final_state['knowledge'].keys():
        result_lines.append("\n" + "=" * 30 + f" å¼‚å¸¸æŒ‡æ ‡: {reason} " + "=" * 30)

        # çŸ¥è¯†åº“è§£å†³æ–¹æ¡ˆ
        result_lines.append("\nğŸ“š çŸ¥è¯†åº“è§£å†³æ–¹æ¡ˆ:")
        result_lines.append(final_state['knowledge'][reason]['solution'])

        # æ¨¡å‹å»ºè®®
        result_lines.append("\nğŸ’¡ å¤§æ¨¡å‹å»ºè®®:")
        result_lines.append(final_state['model_advice'][reason])

        # æ¡ˆä¾‹å‚è€ƒ
        result_lines.append("\nğŸ” ç›¸å…³æ¡ˆä¾‹å‚è€ƒ:")
        result_lines.append(final_state['knowledge'][reason]['case'])

    return "\n".join(result_lines)


def analyze_problem(problem: str, reasons: List[str]) -> Dict:
    """
    æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµåˆ†æ
    
    å‚æ•°:
        problem: æ ¸å¿ƒé—®é¢˜æè¿°
        reasons: éœ€è¦åˆ†æçš„å¼‚å¸¸æŒ‡æ ‡åˆ—è¡¨
        
    è¿”å›:
        {
            "result": åˆ†æç»“æœå­—å…¸,
            "log": å®Œæ•´çš„æ‰§è¡Œæ—¥å¿—,
            "report": æ ¼å¼åŒ–æŠ¥å‘Š
        }
    """
    print("å·¥ä½œæµæœåŠ¡å·²ç»å¯åŠ¨")
    logger.clear()
    try:
        logger.step_start("å¯åŠ¨å·¥ä½œæµ")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # åˆå§‹åŒ–è¾“å…¥çŠ¶æ€
        initial_state: AgentState = {
            "problem": problem,
            "reasons": reasons,
            "knowledge": {},
            "model_advice": {}
        }

        logger.step_info(f"åˆå§‹é—®é¢˜: {initial_state['problem']}")
        logger.step_info(f"å¾…åˆ†æå¼‚å¸¸æŒ‡æ ‡: {', '.join(initial_state['reasons'])}")

        # åˆ›å»ºå¹¶æ‰§è¡Œå·¥ä½œæµ
        workflow = create_workflow()
        logger.step_info("å·¥ä½œæµåˆ›å»ºå®Œæˆï¼Œå¼€å§‹æ‰§è¡Œ...")

        # æ‰§è¡Œå·¥ä½œæµ
        final_state = workflow.invoke(initial_state)

        # ç”ŸæˆæŠ¥å‘Š
        report = visualize_final_result(final_state)

        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = round(time.time() - start_time, 2)
        
        # æ„é€ è¿”å›ç»“æœ
        result = {
            "problem": final_state["problem"],
            "knowledge": final_state["knowledge"],
            "model_advice": final_state["model_advice"],
            "status": "success",
            "execution_time": f"{execution_time}ç§’",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        }
        
        logger.step_success(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼è€—æ—¶{execution_time}ç§’")
        
        return {
            "result": result,
            "log": logger.get_output(),
            "report": report
        }
        
    except Exception as e:
        error_msg = f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.step_warning(error_msg)
        
        return {
            "result": {
                "problem": problem,
                "knowledge": {},
                "model_advice": {},
                "status": "error",
                "error": error_msg,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
            },
            "log": logger.get_output(),
            "report": "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯"
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹è°ƒç”¨
    analysis_result = analyze_problem(
        "production_efficiency",
        ["inventory_turnover_rate", "work_hours", "defect_rate", "completion_rate"]
    )
    
    # æ‰“å°æ—¥å¿—
    print(analysis_result["log"])
    
    # æ‰“å°æŠ¥å‘Š
    print(analysis_result["report"])
    
    # è®¿é—®ç»“æœæ•°æ®
    print("\nåˆ†æç»“æœæ•°æ®:")
    print(json.dumps(analysis_result["result"], indent=2, ensure_ascii=False))